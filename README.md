# üì¶ Previs√£o de Lead Time de Delivery com Machine Learning

Este projeto tem como objetivo analisar e comparar o desempenho de cinco algoritmos de Machine Learning na tarefa de prever o tempo de entrega de pedidos de comida por delivery. Utilizando um dataset p√∫blico disponibilizado no Kaggle, o projeto foi desenvolvido em um ambiente Jupyter Notebook e inclui etapas de limpeza, an√°lise explorat√≥ria de dados (EDA), engenharia de features e avalia√ß√£o de modelos preditivos.

A proposta √© entender quais vari√°veis mais influenciam no tempo de entrega e identificar o modelo com melhor performance para esse tipo de previs√£o, o que pode ser √∫til para empresas do setor de delivery otimizarem suas opera√ß√µes e oferecerem uma experi√™ncia mais precisa aos clientes.


## An√°lise explorat√≥ria de dados

A primeira etapa do projeto consiste em explorar o dataset visualmente, compreendendo sua estrutura, tipos de vari√°veis e poss√≠veis inconsist√™ncias. Para isso, utilizamos a biblioteca Pandas para carregar os dados e visualizar as primeiras linhas da tabela, facilitando o entendimento inicial do conjunto de dados:

![image](https://github.com/user-attachments/assets/90d5988b-196d-4e5d-84c7-3e5e803bb3b4)


O dataset cont√©m vari√°veis categ√≥ricas e num√©ricas, e cada tipo foi analisado separadamente para uma melhor compreens√£o dos dados.
Para as colunas categ√≥ricas, o foco est√° em identificar os valores √∫nicos presentes no conjunto de dados, o que ajuda a entender a variedade de categorias e poss√≠veis inconsist√™ncias ou valores inesperados.

<img width="1300" height="408" alt="image" src="https://github.com/user-attachments/assets/b885e6da-e3ca-4dc6-9b54-80eec97b3523" />

Para as vari√°veis num√©ricas, utilizamos o m√©todo .describe() do Pandas, que retorna um resumo estat√≠stico com as principais medidas descritivas, como m√©dia, desvio padr√£o, valores m√≠nimo e m√°ximo, e os quartis.

<img width="1295" height="383" alt="image" src="https://github.com/user-attachments/assets/b4f0d498-9e0b-4ef3-b79d-51051d0bf4e8" />

## Limpeza do dataset

J√° no passo anterior, removemos os registros com valores nulos (ausentes) j√° que √© necess√°rio que todas as informa√ß√µes sejam presentes para que o registro da entrega fa√ßa sentido. Al√©m disso, a an√°lise incial das distribui√ß√µes das vari√°veis num√©ricas indicam a presen√ßa de outliers. 
Para detectar esses dados, √© utilizado o m√©todo zcores onde √© definido que quaisquer valores acima de 3 desvios-padr√£o da m√©dia √© considerado um ponto que n√£o representa a performance geral do processo:

<img width="1302" height="524" alt="image" src="https://github.com/user-attachments/assets/252b960a-bd58-42bf-8474-149b62387ca4" />

## Engenharia de Features
Antes de prosseguir para o treinamento de modelos de regress√£o, √© necess√°rio aplicar algumas t√©cnicas de engenharia de features. 
A primeira √© a Label-Encoding na vari√°vel "Traffic_Level", j√° que correspondem a uma rela√ß√£o de n√≠veis de tr√°fego do mais baixo at√© o mais alto (ordenados por grau de dificuldade de transitar):

<img width="1301" height="525" alt="image" src="https://github.com/user-attachments/assets/034c84d0-3fd7-44f9-a856-a102c650e4aa" />

O One-Hot encoding √© aplicado para as demais vari√°veis j√° que n√£o h√° um n√∫mero alto de categorias, portanto n√£o gera um alto n√∫mero de colunas com essa transforma√ß√£o:

<img width="1303" height="331" alt="image" src="https://github.com/user-attachments/assets/56fd5574-f5b6-4373-b6b9-261de8373ad4" />

## Visualiza√ß√£o da rela√ß√£o de dados quantitativos:

<img width="986" height="1023" alt="image" src="https://github.com/user-attachments/assets/d2052546-0571-4a39-8016-e3254d5be5e8" />


## Treinando modelos
S√£o testados 5 modelos de regress√£o nas condi√ß√µes padr√£o do pacote Scikit learn avaliando o coeficiente de determina√ß√£o (R¬≤ ajustado) para cada um deles.

  1) Regress√£o Linear
  2) Decision Tree
  3) Random Forest
  4) SVR
  5) XGBoost

Cada um deles com split de 20% dos registros para dados de treinamento e 80% de dados de teste:

<img width="1029" height="480" alt="image" src="https://github.com/user-attachments/assets/36946713-11ff-489b-b241-09f5505a9c64" />

A regress√£o linear tem o melhor resultado entre os modelos √† princ√≠pio. Por√©m, como os par√¢metros da Random Forest (segundo modelo com melhor ajuste) podem ser tunados, vale o esfor√ßo de otimizar par√¢metros desse modelo:

<img width="1309" height="582" alt="image" src="https://github.com/user-attachments/assets/fd317f8a-d247-4638-b59e-8f15dca92fb6" />

Houve um aumento no coeficiente de determina√ß√£o e a aplica√ß√£o desse modelo na performance de um processo de neg√≥cio t√£o aberto a varia√ß√µes √© poss√≠vel.

<img width="790" height="590" alt="image" src="https://github.com/user-attachments/assets/50e21696-2a3b-4a37-b840-1345badcfe89" />











